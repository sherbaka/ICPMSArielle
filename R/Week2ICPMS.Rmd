---
title: "Week2ICPMSLab"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
```


```{r}
ICPMS<-read.csv("~/ICPMSArielle/Data/ICPMS_tidy_example.csv")

```

```{r}
sample_site<- unique(filter(ICPMS, site!= "MB", site!="")$site)
#excluding method blank and quality control from the list of sites
metals_analyzed<- unique(ICPMS$metal)

#preveiw the lists to check for potential issues
sample_site
metals_analyzed
```

```{r Calibration}
ICPMS_cal <- NULL
for (unique_metal in metals_analyzed) {
  #filtering for a single metal then selecting variables of interest
  cal <- ICPMS %>%
    filter(type == "Cal1" | type == "Cal2" | type == "Cal3") %>%
    filter(metal == unique_metal) %>%
    select(concentration, cps, rsd)
  #weighted linear regression
  w <- 1/(cal$cps*cal$rsd)^2
  model <- lm(cal$cps ~ cal$concentration, weights = w)
  #pulling out relevant info from model
  slope <- model$coefficients[2]
  intercept <- model$coefficients[1]
  slope_std <- summary(model)$coefficients[2,2]
  intercept_std <- summary(model)$coefficients[1,2]
  #plotting cal curve
  plot(cal$cps ~ cal$concentration,
       xlab = paste("Concentration of ", unique_metal, "(ppb)"),
       ylab = "Counts per Second") +
    abline(model, col = "red") +
    title(paste("Calibration for ", unique_metal))
  #storing info from calibration curve
  equation <- tibble(metal = unique_metal, slope, slope_std, intercept, intercept_std)
  ICPMS_cal <- rbind(ICPMS_cal, equation)
}

ICPMS_cal

remove (equation, cal, slope, slope_std, intercept, intercept_std, w, model, unique_metal)


```

```{r}
#function to analyze the samples and add a comment with the inputs and outputs of the functions
#inputs: unique_site (as a character, ex. "A")
#outputs: concentration vector

sample_analysis<-function(unique_site){
  #initiated "for loops" to select a specific sample and a specific metal
  concentration_data <- NULL
  for (unique_metal in metals_analyzed){
    sample <- filter(ICPMS, metal == unique_metal, site == unique_site)
    data <- NULL
 
    for (ID in sample$sample_key) {
      sample_data <- filter(sample, sample_key == ID)
      cal <- filter(ICPMS_cal, metal == unique_metal)
      #convert the cps readings into concentrations
      #sample analysis
      m <- cal$slope
      b <- cal$intercept
      y <- sample_data$cps
      b_e <- cal$intercept_std
      m_e <- cal$slope_std
      x <- (y-b)/m #The units are dependent on the calibration standards (Kg/mL)
      RSD <- ((sample_data$rsd/100)*sample_data$cps)
      CPS <- sample_data$cps 
      #propagate the error in the concetration
      #error propagation
      e_yb <- sqrt((RSD)^2 + (b_e)^2) #error in y-b from calibration
      yb <- CPS - b
      e_x <- x*sqrt((e_yb/yb)^2 +(m_e/m)^2) #error in x from calibration
      #if the "site is not eh method blank, store the concentration data
      
      data <- rbind(data, data.frame(sample_key = ID, x, e_x))
      if (unique_site != "MB"){
        concentration_data <- data_frame(sample_key = sample_data$sample_key,
                                         analyst = sample_data$analyst,
                                         metal = unique_metal,
                                         site = unique_site,
                                         conc_dil = x,
                                         conc_dil_error = e_x) %>%
                          rbind(concentration_data)
      }
    }
    #if the site is the method blank, average the concentrations and then store the data
    if (unique_site == "MB"){
      x <- mean(data$x)
      e_x <- sd(data$x)
      concentration_data <- data_frame(metal = unique_metal,
                                       site = unique_site,
                                       conc_dil = x,
                                       conc_dil_error = e_x) %>%
        rbind(concentration_data)
    }
  }
  return(concentration_data)

  
}

```


```{r}
#create a function that runs a different function on each of the soil sample sites

#inputs: a function
#outputs: a data frame with the function outputs from each site

run_sites<-function(Function){
  value <- NULL
  for(sites in sample_site){
    site_value <- Function(sites)
    value <-rbind(site_value, value)
  }
  return(value)
}


```

```{r}
#analyze the method blank and all the samples
MB<- sample_analysis("MB") #ug/kg
uncor_sample<- run_sites(sample_analysis)
#values do not account for dilutns
MB
uncor_sample


```

```{r}
#correct for the method blank and perform error propagation as needed
sample_data_mb <- NULL
for(unique_metal in metals_analyzed){
  MB_metal <- filter(MB, metal==unique_metal)
  sample_metal<- filter(uncor_sample, metal==unique_metal)
  conc_dil_blanked<- sample_metal$conc_dil-MB_metal$conc_dil
  
  #error propogation: subtraticoon of MB
  conc_dil_blanked_error <- sqrt((sample_metal$conc_dil_error)^2 +(MB_metal$conc_dil_error)^2)
  
  sample_data_mb<-sample_metal%>%
    mutate(conc_dil_blanked, conc_dil_blanked_error)%>%
    rbind(sample_data_mb)

}
sample_data_mb
```

```{r}
#define the dilution factors and measuremnt errors
#error propagation
vol_e <- 1
mass_e <- 0.001
dil_1010_e <- sqrt(1^2 + 10^2)
dil_e <- sqrt((dil_1010_e/1010)^2 + (1/10)^2) #error in 101 dilution factor

#correct for dilutions and propagate error
sample_data <- merge(ICPMS, sample_data_mb) %>%
  unique() %>%
  mutate(conc_blanked = conc_dil_blanked*(total_volume/1000)/(mass_of_soil/1000)*101,
         #101 is the factor diluted by at OHSU to make the solutions dilute enought to run the ICPMS on
         conc_blanked_error = conc_blanked *   
           sqrt((conc_dil_blanked_error/conc_dil_blanked)^2 + 
           (dil_e/101)^2 +
           (mass_e/mass_of_soil)^2 +
           (vol_e/total_volume)^2),
         conc_unblanked = conc_dil*(total_volume/1000)/(mass_of_soil/1000)*101,
         conc_unblanked_error = conc_unblanked*
           sqrt((conc_dil_error/conc_dil)^2 +
                  (dil_e/101)^2 +
                  (mass_e/mass_of_soil)^2 +
                  (vol_e/total_volume)^2)) %>%
  select(-concentration, #removing uneccesary columns
         -type,
         -mass_of_soil,
         -total_volume,
         -cps,
         -rsd,
         -conc_dil_blanked,
         -conc_dil_blanked_error,
         -conc_dil,
         -conc_dil_error)

```


```{r, warning=FALSE}
#cleaning up the environment
rm(list=ls()[!(ls()%in% c("ICPMS", "sample_data"))])

```


```{r}
#now i am going to take the averages of all the metals and create a new data frame with that, not sure if I will be able to make a fucntion, i may just do it by hand

###Just testing this method, not really what I need
##sample_data2<-aggregate(sample_data[, 6:9], list(sample_data$metal), mean)

#just grouping by metals for avgs, no qc site or mb
#similar to gillians code
AVG_concMETAL<- sample_data%>%
  filter(site!= "QC")%>%
  group_by(metal)%>%
  summarise(mean_conc = mean(conc_blanked), sd_conc = sd(conc_blanked), n = n()) %>%
    mutate(CI = qnorm(0.975)*sd_conc/sqrt(n),
         lower_ci = mean_conc - CI,
         upper_ci = mean_conc + CI)

#avg of metla per site
AVG_concSITE<- sample_data%>%
  filter(site!= "QC")%>%
  group_by(metal,site)%>%
  summarise(mean_conc = mean(conc_blanked), sd_conc = sd(conc_blanked), n = n()) %>%
    mutate(CI = qnorm(0.975)*sd_conc/sqrt(n),
         lower_ci = mean_conc - CI,
         upper_ci = mean_conc + CI)

#QC site avgs
AVG_concQC<- sample_data%>%
  filter(site== "QC")%>%
  group_by(metal)%>%
  summarise(mean_conc = mean(conc_blanked), sd_conc = sd(conc_blanked), n = n()) %>%
    mutate(CI = qnorm(0.975)*sd_conc/sqrt(n),
         lower_ci = mean_conc - CI,
         upper_ci = mean_conc + CI)


```



```{r}
#Lets create somehting they have in commone to merge the two tables together
AVG_concQC$site <- "QC"
AVG_concMETAL$site <- "NA"
#merging them
AVG_conc=full_join(AVG_concMETAL,AVG_concQC,by=c("metal", "mean_conc", "sd_conc", "n", "CI", "lower_ci", "upper_ci", "site"))
write.csv(AVG_conc, "~/ICPMSArielle/Data/AVG_conc.csv")
```


```{r}
#I found this function on stack exchange
#https://stats.stackexchange.com/questions/30394/how-to-perform-two-sample-t-tests-in-r-by-inputting-sample-statistics-rather-tha

# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0. 
# equal.variance: whether or not to assume equal variance. Default is FALSE. 
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
    if( equal.variance==FALSE ) 
    {
        se <- sqrt( (s1^2/n1) + (s2^2/n2) )
        # welch-satterthwaite df
        df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
    } else
    {
        # pooled standard deviation, scaled by the sample sizes
        se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) ) 
        df <- n1+n2-2
    }      
    t <- (m1-m2-m0)/se 
    dat <- c(m1-m2, se, t, 2*pt(-abs(t),df))    
    names(dat) <- c("Difference of means", "Std Error", "t", "p-value")
    return(dat) 
}

```

```{r}
t.test2(3244.505905, 13945.41904,1335.144796, 2633.02005,22, 12)


```



```{r}


```


